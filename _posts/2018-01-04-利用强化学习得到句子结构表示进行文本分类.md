---
title: 利用强化学习得到句子结构表示进行文本分类
categories:
- 自然语言处理
tags:
- 强化学习
- LSTM
updated: 2018-01-4
---
![](/assets/blog_images/2018-01-04-title.png)
论文链接：[传送门](http://aihuang.org/static/papers/AAAI2018_ClassifyAndStructure.pdf)

### 简介
本文主要研究问题是在文本分类中利用强化学习得到更好的句子的结构化表示，并利用该表示得到了更好的分类效果。文中作者提出了两种学习句子结构化表示的方法ID-LSTM和HS-LSTM；ID-LSTM指将句子中无关的单词删除，只选取重要的、任务相关的单词，HS-LSTM指在句子中划分出更有效的短语结构。

### 模型
![](/assets/blog_images/2018-01-04-model.png)
本论文模型主要分为三部分：策论网络(PNet)，结构表示模型(SRM)，分类网络(CNet)；PNet主要用来指导句子结构模型的生成，接收SRM的state并返回一个action；SRM将原来的句子生成特定结构的模式给CNet分类；CNet分类句子并将分类结果(delayed reward)反馈给PNet让其进行策略优化。
-结构表示模型：
1. ID-LSTM：在句子中保留有用的单词，删除无关的单词。对于输入句子，每个单词都有一个动作{Retain, Delete}；然后根据从PNet获得的动作系列a于LSTM中执行以下操作：
![](/assets/blog_images/2018-01-04-g1.png)
传回去给PNet的state为以下：<br>
![](/assets/blog_images/2018-01-04-g2.png)
2. HS-LSTM：将句子划分为更有效的短语结构。对于输入的句子，每个单词后有一个动作{Inside,End}；HS-LSTM里有两个层次的LSTM结构，单词层次和短语层次,两者共同决定句子的短语结构:
![](/assets/blog_images/2018-01-04-g3.png)
传回去给PNet的state为以下：<br>
![](/assets/blog_images/2018-01-04-g4.png)
最后两种句子结构表示如下所示：
![](/assets/blog_images/2018-01-04-g5.png)

### 实验
分别于MR、SST、Subj、AG四个数据集上进行测试，baselines包括没有特定句子结构方法LSTM、Bi-LSTM、CNN；预先定义好的短语结构方法RAE和Tree-LSTM；基于注意力模型方法Self-Attentive；与基于强化学习得到的ID-LSTM和HS-LSTM句子结构模型对比实验结果如下：
![](/assets/blog_images/2018-01-04-experiment.png)

### 思考
利用强化学习将分类器结果作为reward进行策略优化**学习句子的结构化表示**并提升分类器效果的方法，可以应用到自然语言处理的其他任务中，可以应用在不平衡数据分类中，通过**学习数据抽样**来提升分类器效果
