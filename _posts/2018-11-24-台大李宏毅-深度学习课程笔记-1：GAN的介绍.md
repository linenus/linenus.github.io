---
title: 台大李宏毅-深度学习课程笔记-1：GAN的介绍
categories:
- 台大李宏毅-深度学习
- 生成模型
tags:
- GAN
updated: 2018-11-24
---
## 1 生成模型回顾
生成模型可以做一些有趣的事情，比如写诗，画动漫头像等。
### 1.1 Auto-encoder
![](/assets/blog_images/2018-11-24-自编码.png)
通过Encoder将一张图片变成一个Code vector，然后用一个Decoder将此Code vector生成一张图像，训练过程中让输入的图片跟输出的图片尽可能地相似；最终训练好的Decoder可以充当一个生成器。比如手写数字训练出来的Decoder，其生成的Coder vector假设为2维，我们输入一个二维向量[1.5,0]生成的手写数字可能是1，输入一个二维向量[-1.5,0]生成的手写数字可能是0。
![](/assets/blog_images/2018-11-24-手写数字自编码.png)
如果二维向量的值在[−1.5,0]和[1.5,0]之间等距离取值的话，可能得到如下的结果：
![](/assets/blog_images/2018-11-24-数字生成.png)
Encoder产生的Code vector可以生成图片，但是随机产生的Code vector却不一定能生成图片，因此需要对Encoder产生的Code vector做一些限制，例如让Encoder产生的Code vector服从正态分布，然后我们只需从正态分布中随机产生Code vector输入Decoder就能产生图片了。这正是VAE(Variational Auto-Encoder)的主要思想。
### 1.2 VAE
![](/assets/blog_images/2018-11-24-VAE.png)
VAE是一个进阶版的Auto-encoder，训练的时候，输入一张图片，但是它同时输出两个vector，假设这两个vector都是3维的，分别为表示均值的$m_1$,$m_2$,$m_3$和表示方差的$\sigma_1$,$\sigma_2$,$\sigma_3$；然后从一个符合正态分布的数据集中随机sample一个三维vector $e_1$,$e_2$, $e_3$（称为noise）。接下来做以下操作：  
1. 将vector $\sigma_1,\sigma_2,\sigma_3$ 指数化
2. 将第一步指数化之后的值与noise vector $e_1,e_2,e_3$ 相乘
3. 将vector $m_1$,$m_2$,$m_3$与第二步的结果相加，得到结果$c_1,c_2,c_3$
4. 将最后的结果 $c_1,c_2,c_3$ 输入到Decoder网络训练  

VAE的损失代价除了重构误差外，还要加上生成的Code vector与正态分布的KL散度，这部分误差经过数学变换整好表示为：  
$$\sum_{i=1}^3(exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)$$  
我们期望的VAE是它能生成与真实图像越接近越好的图像,但实际上VAE实际模拟过程与人类的有出入,下图蓝色框代表了两种可能出现的情况。很显然，人类可以分辨出左边是比较接近真实的，右边的不那么接近的（黄色框），但是对于VAE（蓝色框）来说它们在损失函数面前是等价的。
![](/assets/blog_images/2018-11-24-VAE问题.png)  
### 1.3 GAN出世
![](/assets/blog_images/2018-11-24-Generation.png)
上图是一个示例，分别迭代多次，每次是一对 Generator 和 Discriminator，不断演化，最后得到较好结果。其中的Generator与VAE中的Decoder类似，输入一个随机的vector，输出一张图。Discriminator是一个二分类器，如果来自真实图像，则输出1，如果来自生成网络产生的图片，则输出0。  
实际上GAN的训练分为两步骤：  
1. 由Generator产生的图片$\hat{x}$与真实图片$x$训练出当前最优判别器$D^\ast$
![](/assets/blog_images/2018-11-24-Discriminator.png)
2. 固定Discriminator的参数，更新Generator的参数，使Generator产生的图片在Discriminator中打分越高越好。
![](/assets/blog_images/2018-11-24-Generator.png)

## 2 GAN的原理
### 2.1 最大似然估计
![](/assets/blog_images/2018-11-24-MLE.png)
![](/assets/blog_images/2018-11-24-MLE2.png)
然而，高斯混合模型生成的图像非常模糊，因为高斯混合模型无法真正模拟图像数据分布。
### 2.2 $P_G(x;\theta)$由神经网络表示
$P_G(x;\theta)$能将一个分布（通常为已知分布：高斯分布等）转换成任意的分布去近似实际数据分布$P_{data}$，因为神经网络具有很强的泛化能力。
![](/assets/blog_images/2018-11-24-PG.png)
但是，由于 $P_G(x)=\int xP_{prior}(z)I_{[G(z)=x]}dz$的概率没法枚举所有的$z$来计算，在无法计算似然度的情况下，无法调整参数$\theta$使得网络输出$x$接近真实数据分布，GAN最大的贡献就是解决了这个问题。
### 2.3 GAN的基本思想
![](/assets/blog_images/2018-11-24-GAN1.png)
如何理解$G^\ast=argmin_Gmax_DV(G,D)$，先看最右边的$max_DV(G,D)$,它的意思是选择使得$V(G,D)$函数最大的$D$，假设我们只有三个可能的$G$，实际上由于$G$是一个神经网络，它有无限种可能。下图中，分别对于不同可能的$G$，改变$D$，可以得到不同的$V(G,D)$。对于$G_1$,$G_2$,$G_3$，$max_DV(G,D)$就是图中红色的点，使得$max_DV(G,D)$最小的$G^\ast$明显是$G_3$。
![](/assets/blog_images/2018-11-24-GAN2.png)
当V函数定义为：
$$V=E_{x\sim P_{data}}[logD(x)]+E_{x\sim P_G}[log(1-D(x)]$$
**其中$max_DV(G,D)$刚好就是衡量分布$P_{data}$与分布$P_G$之间的差异**，推导如下：
![](/assets/blog_images/2018-11-24-GAN3.png)
![](/assets/blog_images/2018-11-24-GAN4.png)
![](/assets/blog_images/2018-11-24-GAN5.png)
![](/assets/blog_images/2018-11-24-GAN6.png)
![](/assets/blog_images/2018-11-24-GAN7.png)
由上面可以看出，对于给定$G$，$max_DV(G,D)$可以看做计算$-2log2+2JSD(P_{data}||P_G)$，JSD的取值在0到log2之间，当$P_{data}$=$P_G$时，$max_DV(G,D)$取得最小值，也就是两个分布差异最小化。

### 2.4 算法流程
实际上，求解$G^\ast$时，它的$loss$函数就是$max_DV(G,D)$，而对于含有$max$的$loss$函数实际上同样符合梯度下降法求解的，如下图所示
![](/assets/blog_images/2018-11-24-GAN8.png)
![](/assets/blog_images/2018-11-24-GAN9.png)
对于$V$函数中的期望，通常通过采样的方法近似求解，然后发现Maximize $V$函数与Minimize二分类的交叉熵是等价的。因此可以将$D$视为一个参数为$\theta_D$的二元分类器，从$P_{data}$中抽取出来$x_1,x_2,...,x_m$作为正样本，从$P_G$中产生的$\hat{x}_1,\hat{x}_2,...,\hat{x}_m$作为负样本，训练过程中Minimize交叉熵也是Maximize $V(G,D)$。
![](/assets/blog_images/2018-11-24-GAN10.png)
最后，GAN算法的伪代码流程如下图：
![](/assets/blog_images/2018-11-24-GAN11.png)
真正实现时，Generator的目标函数会改成下图中的样子，因为$log(1-D(x))$的曲线在$D(x)$很小时，曲线很平滑，$D(x)$很小意味着，由Generator产生出来的$x$无法骗过Discriminator，Discriminator可以很容易认出；在训练的初始步骤，由Generator产生的样本都集中在平滑部分，此时的$log(1-D(x))$微分值很小，训练变得缓慢。修改后可以加速训练，在初始步骤微分值很大，在后续步骤变得很小，比较符合训练目标。**但是这个在理论上并没有什么保证**，之后的WGAN会改善这里。
![](/assets/blog_images/2018-11-24-GAN12.png)

### 2.5 如何评估JS divergence
我们将Discriminator的$loss$就是来衡量JS divegence，$loss$越大，divergence越大。实际上Discriminator的$loss$告诉我们很少信息，如下图DCGAN最后训练出来的图片已经很真实了，然而discriminator的$loss$还是很大。
![](/assets/blog_images/2018-11-24-GAN14.png)
![](/assets/blog_images/2018-11-24-GAN13.png)
上图中分别衡量的三个Generator，分别训练了1个epoches，10个epoches，25个epoches。其中训练了25个epoches的generator已经几乎可以state of art了，但是用这些Generator去训练discriminator时，discriminator依然有十分高的准确率；导致这个问题的主要原因有以下两点：  
- 我们在训练和调整$D$的时候，不是真正用积分去计算，而是通过抽样来拟合。现在假设我们有红色和蓝色两个椭圆的数据点分布如下，因为我们是使用抽样的方式来代表数据分布
![](/assets/blog_images/2018-11-24-GAN15.png)
即便Generator产生的数据样本与真实样本之间有重叠，但是由于Discriminator比较强，所以它依然能找到一条曲线将红色点和蓝色点区分开。如何解决这个问题？使得Discriminator 变弱一点，少更新，加dropout。但是一个弱Discriminator将导致JS divergence无法计算。  
- $P_G$和$P_{data}$都是高维空间数据，现在假设它们都是二维空间的，那么$P_G$和$P_{data}$以看做二维空间里面的两条直线，那么这两条之间的交集非常小，几乎趋近于零（如下两条直线）。
![](/assets/blog_images/2018-11-24-GAN16.png)
所以真实$P_G$和$P_{data}$的情况可能像下面这样演化：

可以看到在$P_{G_0}$和$P_{G_{50}}$...到$P_{G_{100}}$之前，JS divergence都是log2，GAN没有演化的动力。
### 2.6 如何解决GAN无法优化的问题
- 加入噪音数据。在Discriminator的输入中加入一些人工噪音数据
- 训练Discriminator时，将其label加噪音。比如有张图片是positive，现在随机替换图像的部分内容为噪音。
加入噪音数据之后，原本交集非常少的$P_G$和$P_{data}$就可能会拓宽。
![](/assets/blog_images/2018-11-24-GAN18.png)
**但是噪音数据要随着训练的推荐，逐步减小**

## 3 mode collapse
比如有真实的数据分布为蓝色，而Generator生成的数据分布为红色，如下左图，右边是对应生成的图像。
![](/assets/blog_images/2018-11-24-GAN19.png)
现在问题是，我们只知道GAN生成了的数据，无法知道GAN没有生成的数据,比如戴帽子的动漫头像可能没有生成。  
假设当前$P_{data}$的数据分布如下，为8个黑点。
![](/assets/blog_images/2018-11-24-GAN20.png)
我们训练过程中会出现不一致的情况；比如，我们期望$P_G$可以慢慢去覆盖$P_{data}$；但是实际训练时$P_G$一直只产生一个数据分布点，不断去调整，但始终无法覆盖所有的$P_{data}$
![](/assets/blog_images/2018-11-24-GAN21.png)
可能的原因是之前的损失函数定义，即KL divergence定义有误。下图左边代表了原始的损失函数定义。
![](/assets/blog_images/2018-11-24-GAN22.png)
左边当$P_{data}$有值，而$P_G$为零的时候，该函数将取无穷大的值。所以此时$P_G$为了避免这种情况会尽力去覆盖尽所有的$P_{data}$。  
同样看上图右边，此时当$P_G$有值，而$P_{data}$没有值的时候函数取值会趋近无穷大，此时$P_G$会尽可能拟合一个数据分布(假设真实的$P_{data}$由多个分布组成的话)。

